{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schrödinger's Equation\n",
    "\n",
    "One of the most important governing equations in all of physics. If you do anything to do with quantum mechanics, chances are you'll be dealing with Schrödinger's Equation in one form or another.\n",
    "\n",
    "The Time Dependent Schrödinger Equation (TDSE) in one (spatial) dimension is written:\n",
    "\n",
    "$$ i \\hbar \\frac{\\partial}{\\partial t} \\Psi (x, t) = \\hat{\\mathbf{H}} \\Psi (x,t) $$\n",
    "\n",
    "where $\\hat{\\mathbf{H}}$ is the hamiltonian defined as $\\hat{\\mathbf{H}} = - \\frac{\\hbar^2}{2m} \\frac{\\partial^2}{\\partial x^2} + V(x,t) $ and $\\Psi(x,t)$ is the wave function.\n",
    "\n",
    "In general, this is not an easy partial differential equation (PDE) to solve. Fortunately, with a few mild assumptions, we can simplify the equation to the Time Independent Schrödinger Equation (TISE):\n",
    "\n",
    "First we assume our potential energy function is independent of time $V(x,t) = V(x)$. Then look for solutions of the form $\\Psi(x,t) = \\psi(x) \\phi(t)$ for some $\\psi(x)$ and $\\phi(t)$.\n",
    "\n",
    "$$ \\hat{\\mathbf{H}} \\psi(x) = E \\psi(x) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Solving half of the problem for good\n",
    "\n",
    "Given only the assumptions and notation above, solve the TDSE for $\\phi(t)$ for all possible $V(x)$.\n",
    "\n",
    "Hint: plug in $\\Psi(x,t)=\\psi(x)\\phi(t)$ to the TDSE, apply the TISE, and solve the resulting first order ordinary differential equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Solving Schrödinger's Equation Numerically (For Particle in the Box)\n",
    "\n",
    "The TISE is nothing more than an eigenvalue equation, so if we can write our hamiltonian as a matrix, then all we have to is solve for the eigenvalues and eigenvectors/eigenfunctions and we'll have $\\psi(x)$, and since you already found $\\phi(t)$, then we'll know everything we could possibly want to about our system!\n",
    "\n",
    "If you hear \"numerically\" in the context of python, you know what's coming... some `numpy` magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two especially useful `numpy` functions we'll need here:`linalg.eig` and `eye`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.eig?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick to representing our hamiltonian as a matrix is discretization. See details in the lecture notes, but the notation below should be very similar.\n",
    "\n",
    "We'll be simulating a toy system with arbitrary units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "L = 100\n",
    "\n",
    "def V(x): # Return the potential energy given the position of each grid element\n",
    "    return 0 * x # In this case, we are setting the potential energy to zero.\n",
    "\n",
    "eta = 1\n",
    "m = 1\n",
    "q = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0,L,num=N) - L/2\n",
    "a = X[1] - X[0] # grid spacing\n",
    "\n",
    "t = -eta**2 / (2 * m * a**2)\n",
    "eps = -2*t + q * V(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = t*np.eye(N, k=-1) + eps*np.eye(N) + t*np.eye(N, k=1) # discretized hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're ever curious about what your matrix actually looks like, you can plot it using `matshow`. And mouse over elements to see their values. Note that our hamitonian has offdiagonal elements, where do they come from and why do we need those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually solve the TISE for the energies and wavefunctions using `linalg.eig`.\n",
    "\n",
    "That brings up an interesting question: We only have one equation, but we are solving this one equation for two unknowns (the wavefunction, and the energy), thinking back to linear algebra, shouldn't this problem be underdetermined? That is to say, how is it that we can use a single equation to solve for both the wavefunction and energy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = np.linalg.eig(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately `linalg.eig` does not return the eigenvalues/vectors sorted, but that can be fixed with a little `numpy` magic. Make sure you understand how to two lines below work - tricks like these can dramatically speed up your work.\n",
    "Also, since our `vecs` variable holds column vectors we can flip those to row vectors in the last line. We also have to normalize our wavefunctions (given the grid spacing that we were using)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(vals)\n",
    "vals, vecs = vals[order], vecs[:, order]\n",
    "vecs = vecs.T\n",
    "vecs /= np.sqrt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the eigenvalues (which correspond to the energies of each state) and the eigenvectors (which are the states, aka wavefunctions).\n",
    "\n",
    "Before plotting the energy spectrum below, what do you expect the energies will look like, given that our potential energy  is zero accross the entire wire (V=0)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(vals)\n",
    "plt.title('Energy spectrum of our solutions')\n",
    "plt.xlabel('Level')\n",
    "plt.ylabel('Energy (arb. units)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this spectrum look as expected? If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can plot the first few wavefunctions and corresponding energies we found. But you already know what to expect, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plt.title('Wavefunctions of a Particle in a box')\n",
    "for i, (ax, psi, E) in enumerate(zip(axes, vecs, vals)):\n",
    "    plt.sca(ax)\n",
    "    plt.ylabel('Psi {}'.format(i))\n",
    "    plt.plot(X, psi)\n",
    "    #plt.fill_between(X, psi, alpha=0.3)\n",
    "    print('E_{} = {:.4f}'.format(i, E))\n",
    "plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is theoretically all fine and good, being learned in the ways of quantum mechanics we know that the wavefunction is not directly measurable. Instead, if we measure for example the position of our particle, the actual outcome of our measurement will be one of the eigenvalues of the position operator. Fortunately, we have been working in the position basis (solving for our wavefunction as a function of $x$), so we can get the probability distribution over possible measurement outcomes directly from our wavefunction:\n",
    "\n",
    "$$ p(x) = |\\psi(x)|^2 $$\n",
    "\n",
    "where $p(x)$ is the probability density function of outcomes from position measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.abs(vecs)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the probability form our probability density function, all we need is to multiply by $dx$, in our case we have already discretized our wire so $dx = a$.\n",
    "\n",
    "$$ \\mathrm{Prob}(x) = p(x) dx $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = a*p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, sharex=True, sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plt.title('Position distributions of a Particle in a box')\n",
    "for i, (ax, pd) in enumerate(zip(axes, p)):\n",
    "    plt.sca(ax)\n",
    "    plt.ylabel('p_{}(x)'.format(i))\n",
    "    plt.plot(X, pd)\n",
    "    plt.fill_between(X, pd, alpha=0.3)\n",
    "plt.xlabel('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Quantum Harmonic Oscillator\n",
    "\n",
    "#### Part A:\n",
    "Remember, the potential energy of a harmonic oscillators takes the form $V(x) = \\frac{1}{2}kx^2$ where $k$ is the spring constant.\n",
    "In our case, let us use:\n",
    "$$ k = 2.10*10^{-8}  N/m $$\n",
    "$$ m = 9.1*10^{-31}  kg $$\n",
    "$$ \\hbar = 1.054 * 10^{-34} J*s$$\n",
    "\n",
    "Deliverables:\n",
    "- Tabulate the lowest 5 energy levels\n",
    "- Find the value of $\\hbar \\omega$, $E_2 - E_1$, $E_3 - E_2$, and $E_4 - E_3$? \n",
    "\n",
    "\n",
    "#### Part B:\n",
    "Example 1 has the code to compute and plot the 5 lowest energy states of a particle confined to a box from `-L/2` to `L/2`.\n",
    "Now do the same for a particle in a hamronic potential using the parameters given above. Assume that the length of the simulation region is $ L = 0.2 \\mu m$\n",
    "\n",
    "Further assume that the numerical values of the PE are: \n",
    "$$ PE(x)=   \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{1}{2} kx^2 & -0.06um<x<0.06um \\\\\n",
    "      3.78*10^{-23} & Otherwise \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "\n",
    "Plot the PE(x) and realize that it is not perfectly Harmonic. This is usually the case in most realistic situations. Often there are anharmonic corrections to the PE. A common anharmonic correction that is encountered in qubits and crystals is a cubic term ($PE(x) = \\frac{1}{2} kx^2 + \\gamma x^3$).\n",
    "\n",
    "When plotting the energy spectrum of the solutions, once again predict what shape the spectrum should take, and then after plotting explain any differences to your prediction.\n",
    "\n",
    "Deliverables:\n",
    "- Tabulate the lowest 5 energy levels\n",
    "- Find the value of $\\hbar \\omega$, $E_2 - E_1$, $E_3 - E_2$, and $E_4 - E_3$? Is there any differece from what you got in Part A?\n",
    "- Plot of the wavefunctions of the lowest 5 energy levels\n",
    "- Plot of the probability density functions of outcomes of position measurements for the lowest 5 energy levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Harmonic Oscillator Frequencies\n",
    "\n",
    "Once you have the energies of the wavefunctions for the quantum harmonic oscillator, let's make sure they look right.\n",
    "We know the energy levels of the quantum harmonic oscillator states takes the form (see lecture notes for details):\n",
    "\n",
    "$$ E_n = \\eta \\omega (n + \\frac{1}{2}) $$\n",
    "\n",
    "where $n$ is the energy level, $\\eta$ is our natural constant ($\\eta = \\hbar$ in reality), and $\\omega$ is the frequency of our oscillator.\n",
    "\n",
    "You will note the ground state ($n=0$) still has some energy ($E_0=\\frac{\\eta \\omega}{2}$), this is called the zero point energy, and it carries some deep significance in physics. (Among other things, the zero point energy is related to virtual photons predicted by Quantum Field Theory, and possibly even the dark energy in the universe...)\n",
    "\n",
    "Anyway, use the computed energy values for the lowest 5 energy levels to estimate the frequency of our harmonic oscillator. Then use a smaller grid spacing (increase $N$) to make sure your estimate of the frequency has converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Shifts\n",
    "\n",
    "It may seem strange for our wavefunction to be complex valued. The fact of the matter is we trust Schrödinger's equation more than we trust our interpretation of the wavefunction. Mathematically, complex eigenfunctions of the hamiltonian exist, so our interpretation better have an explanation to make sense of this mathematical quirk.\n",
    "\n",
    "The, rather elegant, solution is to recognize that eventhough the wavefunction may be complex, the outcomes of measurements are actually the corresponding eigenvalues, so as long as the eigenvalues are always real, it doesn't matter if eigenfunctions have an imaginary component.\n",
    "\n",
    "Another quirk of the Schrödinger equation is that given any solution $\\Psi(x,t)$, any arbitrary phase shift of $\\Psi(x,t)$ will still be a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Phase of the Wavefunction\n",
    "\n",
    "Show that if $\\Psi(x,t)$ is a solution to the TDSE, then $e^{i\\alpha} \\Psi(x,t)$ (for some fixed $\\alpha$) is also a solution. (Hint: this is a one liner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Time Evolution\n",
    "\n",
    "After turning the TDSE into the TISE using separation of variables, we focused on finding solutions for the TISE, but now that we have solutions for the TISE, we can go back and look at how our system evolves over time.\n",
    "\n",
    "Once we have found a solution $\\psi(x)$ and the corresponding energy $E$ using the TISE, we can combine it with the time component $\\phi(t)$\n",
    "\n",
    "$$ \\hat{\\mathbf{H}} \\psi(x) = E \\psi(x) $$\n",
    "\n",
    "$$ \\phi(t) = e^{-i\\frac{E}{\\hbar}t} $$\n",
    "\n",
    "Now the overall solution to the TDSE is $\\Psi(x,t) = \\psi(x) \\phi(t)$.\n",
    "\n",
    "Let's take a look at how solutions to the particle in the box evolve over time using matplotlib animations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we solve the TISE for the particle in the box, once again, to get the energies and eigenstates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "L = 100\n",
    "\n",
    "def V(x): # Return the potential energy given the position of each grid element\n",
    "    return 0 * x # In this case, we are setting the potential energy to zero.\n",
    "\n",
    "eta = 1\n",
    "m = 1\n",
    "q = 1\n",
    "\n",
    "X = np.linspace(0,L,num=N) - L/2\n",
    "a = X[1] - X[0] # grid spacing\n",
    "\n",
    "t = -eta**2 / (2 * m * a**2)\n",
    "eps = -2*t + q * V(X)\n",
    "\n",
    "# Define discretized hamiltonian\n",
    "H = t*np.eye(N, k=-1) + eps*np.eye(N) + t*np.eye(N, k=1)\n",
    "\n",
    "# Solve TISE to get wavefunctions and energies\n",
    "vals, vecs = np.linalg.eig(H)\n",
    "order = np.argsort(vals)\n",
    "vals, vecs = vals[order], vecs[:, order]\n",
    "vecs = vecs.T\n",
    "# Normalize wavefunction\n",
    "vecs /= np.sqrt(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function for matplotlib to call during the animation to get the state (wavefunction) at particular time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(psi, E, timestep=5, num_step=200):\n",
    "    ts = np.arange(num_step)*timestep\n",
    "    t = 0\n",
    "    cnt = 0\n",
    "    while num_step is None or cnt < num_step:\n",
    "        phase = np.exp(- 1j * E / eta * t)\n",
    "        cnt += 1\n",
    "        t += timestep\n",
    "        yield t, phase * psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can choose what the state of the particle should be, where `level = 0` corresponds to the ground state, `level = 1` to the first excited state etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 3\n",
    "psi = vecs[level].astype(np.complex64)\n",
    "E = vals[level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = evolve(psi, E)\n",
    "\n",
    "print('Real component in red, imaginary in blue')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "ax1.set_title('Wavefunction')\n",
    "ax1.set_ylabel('psi(x)')\n",
    "ax2.set_title('Probability Density')\n",
    "ax2.set_ylabel('p(x)')\n",
    "ax2.set_xlabel('x')\n",
    "wave = psi\n",
    "wave_real, = ax1.plot(X, wave.real, c='b')\n",
    "wave_imag, = ax1.plot(X, wave.imag, c='r')\n",
    "p = np.abs(wave)**2\n",
    "dens, = ax2.plot(X, p, color='k')\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "lim = np.sqrt(p).max()+0.1\n",
    "ax1.set_ylim(-lim, lim)\n",
    "ax2.set_ylim(-1e-4, max(p)+0.02)\n",
    "\n",
    "def run(data): # this updates the plot at every timestep given the wavefunction at the new time\n",
    "    t, wave = data\n",
    "    \n",
    "    ax1.set_title('Wavefunction (t={:.2f})'.format(t))\n",
    "    wave_real.set_data(X, wave.real)\n",
    "    wave_imag.set_data(X, wave.imag)\n",
    "\n",
    "    p = np.abs(wave)**2\n",
    "    dens.set_data(X, p)\n",
    "    \n",
    "    return wave_real, wave_imag, dens\n",
    "\n",
    "ani = animation.FuncAnimation(fig, run, evolution, blit=False, interval=10, repeat=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how eventhough the wavefunction is changing over time, the resulting probability density over positions doesn't change. We call the eigenstates of the hamiltonian stationary because the time dependence only changes the overall phase of the state, which does not affect any observable property of our particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Wavefunctions Oscillate\n",
    "\n",
    "As the time evolution of our stationary states is given by $ e^{-i\\frac{E}{\\hbar}t} $, we know our wavefunction oscillates with time.\n",
    "\n",
    "Given a particle in the box in the second excited state $\\psi_2$ with $\\eta = 1$, $m = 1$, $L = 100$, and $N = 100$ (using the notation in the code, $a \\approx 1$). If the wavefunction of our particle is entirely real at $t = 0$, what is the smallest amount of time we have to wait before the wavefunction is once again entirely real?\n",
    "\n",
    "Compare the result you get empirically (using the numerical approach in Example 2) to what you would expect in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your answer here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
